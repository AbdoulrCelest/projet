{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T09:05:39.457391Z",
     "start_time": "2025-06-14T09:05:39.229788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import keras_tuner as kt\n",
    "import json\n",
    "\n",
    "# ğŸ“ Chemin des datasets Parquet\n",
    "DATA_DIR = \"processed\"\n",
    "MODEL_DIR = \"models\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "def create_sequences(df, target_col, lookback, features):\n",
    "    data = df[features]\n",
    "    X, y = [], []\n",
    "    for i in range(lookback, len(data)):\n",
    "        X.append(data.iloc[i - lookback:i].values)\n",
    "        y.append(data.iloc[i][target_col])\n",
    "    return np.array(X), np.array(y)\n"
   ],
   "id": "3715ba8e18b922de",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T09:05:39.683412Z",
     "start_time": "2025-06-14T09:05:39.545563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_simple_lstm(hp, input_shape):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(units=hp.Int(\"units\", 32, 128, step=32),\n",
    "                                   input_shape=input_shape))\n",
    "    model.add(tf.keras.layers.Dropout(hp.Float(\"dropout\", 0.0, 0.5, step=0.1)))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(hp.Float(\"lr\", 1e-4, 1e-2, sampling=\"log\")),\n",
    "                  loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "def build_bidirectional_lstm(hp, input_shape):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Bidirectional(\n",
    "        tf.keras.layers.LSTM(units=hp.Int(\"units\", 32, 128, step=32)),\n",
    "        input_shape=input_shape\n",
    "    ))\n",
    "    model.add(tf.keras.layers.Dropout(hp.Float(\"dropout\", 0.0, 0.5, step=0.1)))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(hp.Float(\"lr\", 1e-4, 1e-2, sampling=\"log\")),\n",
    "                  loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "def build_cnn_lstm(hp, input_shape):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv1D(filters=hp.Int(\"filters\", 16, 64, step=16),\n",
    "                               kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "        tf.keras.layers.LSTM(units=hp.Int(\"units\", 32, 128, step=32)),\n",
    "        tf.keras.layers.Dropout(hp.Float(\"dropout\", 0.0, 0.5, step=0.1)),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(hp.Float(\"lr\", 1e-4, 1e-2, sampling=\"log\")),\n",
    "                  loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "def build_stacked_lstm(hp, input_shape):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(units=hp.Int(\"units1\", 32, 128, step=32), return_sequences=True, input_shape=input_shape))\n",
    "    model.add(tf.keras.layers.LSTM(units=hp.Int(\"units2\", 32, 128, step=32)))\n",
    "    model.add(tf.keras.layers.Dropout(hp.Float(\"dropout\", 0.0, 0.5, step=0.1)))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(hp.Float(\"lr\", 1e-4, 1e-2, sampling=\"log\")),\n",
    "                  loss=\"mse\")\n",
    "    return model\n"
   ],
   "id": "877a21bdb0be449b",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T09:56:00.803350Z",
     "start_time": "2025-06-14T09:05:40.348044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ast\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === CONFIG ===\n",
    "TARGET_COL = 'demand'\n",
    "MAX_TRIALS = 10\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "VAL_SPLIT = 0.2\n",
    "\n",
    "def get_features_for_file(zone, horizon):\n",
    "    df1 = pd.read_csv(f'submission/features_selected_{horizon}.csv')\n",
    "    \n",
    "    df1['features'] = df1['features'].apply(ast.literal_eval)\n",
    "    \n",
    "    features = df1.loc[df1['zone'] == zone, 'features'].values[0]\n",
    "    return [col for col in features if col != TARGET_COL]\n",
    "\n",
    "# === ARCHITECTURES DISPONIBLES ===\n",
    "model_builders = {\n",
    "    \"LSTM\": build_simple_lstm,\n",
    "    \"BiLSTM\": build_bidirectional_lstm,\n",
    "    \"CNN_LSTM\": build_cnn_lstm,\n",
    "    \"Stacked_LSTM\": build_stacked_lstm\n",
    "}\n",
    "\n",
    "# === BOUCLE SUR TOUS LES FICHIERS PARQUET ===\n",
    "for filepath in tqdm(glob(f\"{DATA_DIR}/*.parquet\")):\n",
    "    filename = os.path.basename(filepath).replace(\".parquet\", \"\")\n",
    "    try:\n",
    "        filename_base = filename.replace(\".parquet\", \"\")\n",
    "        zone = filename_base.rsplit(\"_processed_\", 1)[0]\n",
    "        horizon = filename_base.rsplit(\"_processed_\", 1)[1]\n",
    "        lookback = 24 if horizon == \"hourly\" else 7\n",
    "    except:\n",
    "        print(f\"Format invalide pour le fichier : {filename}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nProcessing {zone} ({horizon})\")\n",
    "\n",
    "    df = pd.read_parquet(filepath).dropna()\n",
    "    features = get_features_for_file(zone, horizon)\n",
    "\n",
    "    # Assure que target est dans le DataFrame\n",
    "    if TARGET_COL not in df.columns:\n",
    "        print(f\"Colonne '{TARGET_COL}' absente de {filename}\")\n",
    "        continue\n",
    "\n",
    "    df = df[[*features, TARGET_COL]].dropna()\n",
    "    X, y = create_sequences(df, TARGET_COL, lookback, features)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "    best_rmse = float('inf')\n",
    "    best_model_name = \"\"\n",
    "    best_model_instance = None\n",
    "    best_metrics = {}\n",
    "\n",
    "    for model_name, builder in model_builders.items():\n",
    "        print(f\"ğŸ” Tuning {model_name}...\")\n",
    "\n",
    "        tuner = kt.RandomSearch(\n",
    "            lambda hp: builder(hp, input_shape=X_train.shape[1:]),\n",
    "            objective=\"val_loss\",\n",
    "            max_trials=MAX_TRIALS,\n",
    "            overwrite=True,\n",
    "            directory=\"kt_tuning\",\n",
    "            project_name=f\"{zone}_{horizon}_{model_name}\"\n",
    "        )\n",
    "\n",
    "        tuner.search(X_train, y_train, validation_split=VAL_SPLIT,\n",
    "                     epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=0)\n",
    "\n",
    "        best_model = tuner.get_best_models(1)[0]\n",
    "        y_pred = best_model.predict(X_test).flatten()\n",
    "\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_model_name = model_name\n",
    "            best_model_instance = best_model\n",
    "            best_metrics = {\"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}\n",
    "\n",
    "    # === SAUVEGARDE ===\n",
    "    model_filename = f\"{zone}_{horizon}_{best_model_name}.h5\"\n",
    "    metrics_filename = f\"{zone}_{horizon}_metrics.json\"\n",
    "    best_model_instance.save(os.path.join(MODEL_DIR, model_filename))\n",
    "\n",
    "    with open(os.path.join(MODEL_DIR, metrics_filename), \"w\") as f:\n",
    "        json.dump(best_metrics, f, indent=2)\n",
    "\n",
    "    print(f\"Meilleur modÃ¨le pour {zone}_{horizon} : {best_model_name}\")\n",
    "    print(json.dumps(best_metrics, indent=2))\n"
   ],
   "id": "fc73302f8e487b68",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format invalide pour le fichier : Baleares_processed\n",
      "\n",
      "Processing Baleares (daily)\n",
      "ğŸ” Tuning LSTM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 12 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m18/18\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 129ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Tuning BiLSTM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m18/18\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 157ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Tuning CNN_LSTM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 16 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m18/18\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 80ms/step\n",
      "ğŸ” Tuning Stacked_LSTM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "Exception ignored in: <function AtomicFunction.__del__ at 0x00000250C2B12B60>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py\", line 303, in __del__\n",
      "    RUNTIME_FUNCTION_REFS.pop(key)\n",
      "KeyboardInterrupt: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 274, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 239, in _run_and_update_trial\n",
      "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 314, in run_trial\n",
      "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 233, in _build_and_fit_model\n",
      "    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py\", line 149, in fit\n",
      "    return model.fit(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner_utils.py\", line 76, in on_epoch_end\n",
      "    self._save_model()\n",
      "  File \"C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner_utils.py\", line 86, in _save_model\n",
      "    self.model.save_weights(write_filepath)\n",
      "  File \"C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\h5py\\_hl\\files.py\", line 561, in __init__\n",
      "    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\h5py\\_hl\\files.py\", line 241, in make_fid\n",
      "    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"h5py\\\\_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py\\\\_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py\\\\h5f.pyx\", line 122, in h5py.h5f.create\n",
      "FileNotFoundError: [Errno 2] Unable to synchronously create file (unable to open file: name = 'kt_tuning\\Baleares_daily_Stacked_LSTM\\trial_05\\checkpoint.weights.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 302)\n",
      "Exception ignored in: <function WeakKeyDictionary.__init__.<locals>.remove at 0x00000250C2D3F2E0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\weakref.py\", line 370, in remove\n",
      "    self = selfref()\n",
      "           ^^^^^^^^^\n",
      "KeyboardInterrupt: \n",
      "  4%|â–         | 1/25 [50:18<20:07:27, 3018.64s/it]\n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x00000250B59EF5C0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 790, in _clean_thread_parent_frames\n",
      "    active_threads = {thread.ident for thread in threading.enumerate()}\n",
      "                                                 ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1535, in enumerate\n",
      "    def enumerate():\n",
      "    \n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-06-14T09:57:27.637753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import ast\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# === CONFIG ===\n",
    "TARGET_COL = 'demand'\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "VAL_SPLIT = 0.2\n",
    "DATA_DIR = \"processed\"\n",
    "MODEL_DIR = \"models\"   # Ã  adapter\n",
    "\n",
    "# === ModÃ¨les simplifiÃ©s sans Keras Tuner ===\n",
    "def build_simple_lstm_fixed(input_shape):\n",
    "    units = 64\n",
    "    dropout = 0.2\n",
    "    lr = 1e-3\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(units=units, input_shape=input_shape),\n",
    "        tf.keras.layers.Dropout(dropout),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "def build_bidirectional_lstm_fixed(input_shape):\n",
    "    units = 64\n",
    "    dropout = 0.2\n",
    "    lr = 1e-3\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=units), input_shape=input_shape),\n",
    "        tf.keras.layers.Dropout(dropout),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "def build_cnn_lstm_fixed(input_shape):\n",
    "    filters = 32\n",
    "    units = 64\n",
    "    dropout = 0.2\n",
    "    lr = 1e-3\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv1D(filters=filters, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "        tf.keras.layers.LSTM(units=units),\n",
    "        tf.keras.layers.Dropout(dropout),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "def build_stacked_lstm_fixed(input_shape):\n",
    "    units1 = 64\n",
    "    units2 = 64\n",
    "    dropout = 0.2\n",
    "    lr = 1e-3\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(units=units1, return_sequences=True, input_shape=input_shape),\n",
    "        tf.keras.layers.LSTM(units=units2),\n",
    "        tf.keras.layers.Dropout(dropout),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr), loss=\"mse\")\n",
    "    return model\n",
    "\n",
    "# === Fonction pour rÃ©cupÃ©rer features (identique Ã  la tienne) ===\n",
    "def get_features_for_file(zone, horizon):\n",
    "    df1 = pd.read_csv(f'submission/features_selected_{horizon}.csv')\n",
    "    df1['features'] = df1['features'].apply(ast.literal_eval)\n",
    "    features = df1.loc[df1['zone'] == zone, 'features'].values[0]\n",
    "    return [col for col in features if col != TARGET_COL]\n",
    "\n",
    "# === Fonction pour crÃ©er des sÃ©quences (Ã  dÃ©finir selon ton code) ===\n",
    "def create_sequences(df, target_col, lookback, feature_cols):\n",
    "    # Attention : adapter selon ta fonction existante !\n",
    "    X, y = [], []\n",
    "    data = df[feature_cols + [target_col]].values\n",
    "    for i in range(len(df) - lookback):\n",
    "        X.append(data[i:i+lookback, :-1])\n",
    "        y.append(data[i+lookback, -1])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# === Dictionnaire des constructeurs fixes ===\n",
    "model_builders = {\n",
    "    \"LSTM\": build_simple_lstm_fixed,\n",
    "    \"BiLSTM\": build_bidirectional_lstm_fixed,\n",
    "    \"CNN_LSTM\": build_cnn_lstm_fixed,\n",
    "    \"Stacked_LSTM\": build_stacked_lstm_fixed\n",
    "}\n",
    "\n",
    "# === Boucle principale ===\n",
    "for filepath in tqdm(glob(f\"{DATA_DIR}/*.parquet\")):\n",
    "    filename = os.path.basename(filepath).replace(\".parquet\", \"\")\n",
    "    try:\n",
    "        zone, horizon = filename.rsplit(\"_processed_\", 1)\n",
    "        lookback = 24 if horizon == \"hourly\" else 7\n",
    "    except:\n",
    "        print(f\"Format invalide pour le fichier : {filename}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\nProcessing {zone} ({horizon})\")\n",
    "\n",
    "    df = pd.read_parquet(filepath).dropna()\n",
    "    features = get_features_for_file(zone, horizon)\n",
    "\n",
    "    if TARGET_COL not in df.columns:\n",
    "        print(f\"Colonne '{TARGET_COL}' absente de {filename}\")\n",
    "        continue\n",
    "\n",
    "    df = df[[*features, TARGET_COL]].dropna()\n",
    "    X, y = create_sequences(df, TARGET_COL, lookback, features)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "    best_rmse = float('inf')\n",
    "    best_model_name = None\n",
    "    best_model_instance = None\n",
    "    best_metrics = None\n",
    "\n",
    "    for model_name, builder in model_builders.items():\n",
    "        print(f\"Training {model_name}...\")\n",
    "\n",
    "        model = builder(input_shape=X_train.shape[1:])\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_split=VAL_SPLIT,\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        y_pred = model.predict(X_test).flatten()\n",
    "\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        print(f\"{model_name} -> MAE: {mae:.4f}, RMSE: {rmse:.4f}, R2: {r2:.4f}\")\n",
    "\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_model_name = model_name\n",
    "            best_model_instance = model\n",
    "            best_metrics = {\"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}\n",
    "\n",
    "    # Sauvegarde du meilleur modÃ¨le et mÃ©triques\n",
    "    model_filename = f\"{zone}_{horizon}_{best_model_name}.h5\"\n",
    "    metrics_filename = f\"{zone}_{horizon}_metrics.json\"\n",
    "\n",
    "    best_model_instance.save(os.path.join(MODEL_DIR, model_filename))\n",
    "    with open(os.path.join(MODEL_DIR, metrics_filename), \"w\") as f:\n",
    "        json.dump(best_metrics, f, indent=2)\n",
    "\n",
    "    print(f\"Best model for {zone} ({horizon}): {best_model_name}\")\n",
    "    print(json.dumps(best_metrics, indent=2))\n"
   ],
   "id": "76a0a28810558777",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format invalide pour le fichier : Baleares_processed\n",
      "\n",
      "Processing Baleares (daily)\n",
      "Training LSTM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 64ms/step - loss: 257873968.0000 - val_loss: 236116256.0000\n",
      "Epoch 2/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 27ms/step - loss: 256816544.0000 - val_loss: 236067952.0000\n",
      "Epoch 3/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 33ms/step - loss: 254773808.0000 - val_loss: 236019488.0000\n",
      "Epoch 4/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 255377168.0000 - val_loss: 235977072.0000\n",
      "Epoch 5/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 28ms/step - loss: 255427072.0000 - val_loss: 235935904.0000\n",
      "Epoch 6/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 38ms/step - loss: 257276560.0000 - val_loss: 235891568.0000\n",
      "Epoch 7/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 255698160.0000 - val_loss: 235841792.0000\n",
      "Epoch 8/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 27ms/step - loss: 254633264.0000 - val_loss: 235797152.0000\n",
      "Epoch 9/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 34ms/step - loss: 252946624.0000 - val_loss: 235753184.0000\n",
      "Epoch 10/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 251722656.0000 - val_loss: 235710064.0000\n",
      "Epoch 11/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 255744016.0000 - val_loss: 235666304.0000\n",
      "Epoch 12/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 34ms/step - loss: 252467984.0000 - val_loss: 235623648.0000\n",
      "Epoch 13/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - loss: 255535744.0000 - val_loss: 235575264.0000\n",
      "Epoch 14/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 32ms/step - loss: 254354480.0000 - val_loss: 235523792.0000\n",
      "Epoch 15/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 25ms/step - loss: 251013840.0000 - val_loss: 235476704.0000\n",
      "Epoch 16/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 32ms/step - loss: 256099536.0000 - val_loss: 235431072.0000\n",
      "Epoch 17/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 25ms/step - loss: 252467920.0000 - val_loss: 235385936.0000\n",
      "Epoch 18/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 22ms/step - loss: 255187024.0000 - val_loss: 235341024.0000\n",
      "Epoch 19/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 22ms/step - loss: 255221264.0000 - val_loss: 235296736.0000\n",
      "Epoch 20/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 250794464.0000 - val_loss: 235252640.0000\n",
      "\u001B[1m18/18\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 67ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM -> MAE: 16325.1384, RMSE: 17098.7004, R2: -10.3080\n",
      "Training BiLSTM...\n",
      "Epoch 1/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 54ms/step - loss: 259459216.0000 - val_loss: 236156720.0000\n",
      "Epoch 2/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 25ms/step - loss: 252482000.0000 - val_loss: 236108688.0000\n",
      "Epoch 3/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 19ms/step - loss: 254787952.0000 - val_loss: 236051984.0000\n",
      "Epoch 4/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 23ms/step - loss: 256870416.0000 - val_loss: 235994128.0000\n",
      "Epoch 5/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 27ms/step - loss: 257698624.0000 - val_loss: 235942304.0000\n",
      "Epoch 6/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 21ms/step - loss: 250612464.0000 - val_loss: 235884624.0000\n",
      "Epoch 7/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 253789344.0000 - val_loss: 235832240.0000\n",
      "Epoch 8/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 32ms/step - loss: 250624672.0000 - val_loss: 235772576.0000\n",
      "Epoch 9/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 36ms/step - loss: 251474352.0000 - val_loss: 235719392.0000\n",
      "Epoch 10/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 31ms/step - loss: 256320368.0000 - val_loss: 235667824.0000\n",
      "Epoch 11/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 24ms/step - loss: 255827904.0000 - val_loss: 235618960.0000\n",
      "Epoch 12/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 31ms/step - loss: 252673808.0000 - val_loss: 235558560.0000\n",
      "Epoch 13/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 26ms/step - loss: 252482704.0000 - val_loss: 235504272.0000\n",
      "Epoch 14/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 23ms/step - loss: 252049776.0000 - val_loss: 235451264.0000\n",
      "Epoch 15/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 32ms/step - loss: 254020320.0000 - val_loss: 235398832.0000\n",
      "Epoch 16/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 23ms/step - loss: 253836320.0000 - val_loss: 235347216.0000\n",
      "Epoch 17/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 28ms/step - loss: 258809664.0000 - val_loss: 235295600.0000\n",
      "Epoch 18/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 22ms/step - loss: 255803136.0000 - val_loss: 235244672.0000\n",
      "Epoch 19/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 19ms/step - loss: 253362240.0000 - val_loss: 235187056.0000\n",
      "Epoch 20/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 39ms/step - loss: 251277168.0000 - val_loss: 235130640.0000\n",
      "\u001B[1m18/18\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 122ms/step\n",
      "BiLSTM -> MAE: 16321.0506, RMSE: 17094.8248, R2: -10.3029\n",
      "Training CNN_LSTM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 106ms/step - loss: 253614448.0000 - val_loss: 236130304.0000\n",
      "Epoch 2/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 21ms/step - loss: 252133168.0000 - val_loss: 236098528.0000\n",
      "Epoch 3/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 47ms/step - loss: 257055936.0000 - val_loss: 236068208.0000\n",
      "Epoch 4/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - loss: 252756080.0000 - val_loss: 236037840.0000\n",
      "Epoch 5/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 60ms/step - loss: 258122784.0000 - val_loss: 236006272.0000\n",
      "Epoch 6/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 27ms/step - loss: 256373600.0000 - val_loss: 235973520.0000\n",
      "Epoch 7/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 49ms/step - loss: 251054016.0000 - val_loss: 235939168.0000\n",
      "Epoch 8/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 20ms/step - loss: 255866624.0000 - val_loss: 235906400.0000\n",
      "Epoch 9/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 17ms/step - loss: 247556480.0000 - val_loss: 235874208.0000\n",
      "Epoch 10/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 20ms/step - loss: 255252352.0000 - val_loss: 235842224.0000\n",
      "Epoch 11/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 25ms/step - loss: 251698672.0000 - val_loss: 235810432.0000\n",
      "Epoch 12/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 28ms/step - loss: 257500464.0000 - val_loss: 235778768.0000\n",
      "Epoch 13/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 256785184.0000 - val_loss: 235747280.0000\n",
      "Epoch 14/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 38ms/step - loss: 256478528.0000 - val_loss: 235715696.0000\n",
      "Epoch 15/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 18ms/step - loss: 256779440.0000 - val_loss: 235683808.0000\n",
      "Epoch 16/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 33ms/step - loss: 251641120.0000 - val_loss: 235652368.0000\n",
      "Epoch 17/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 255140432.0000 - val_loss: 235621104.0000\n",
      "Epoch 18/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 35ms/step - loss: 260392000.0000 - val_loss: 235589600.0000\n",
      "Epoch 19/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 17ms/step - loss: 248825808.0000 - val_loss: 235558512.0000\n",
      "Epoch 20/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 15ms/step - loss: 256164272.0000 - val_loss: 235527280.0000\n",
      "\u001B[1m18/18\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 124ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_LSTM -> MAE: 16334.3616, RMSE: 17107.4864, R2: -10.3196\n",
      "Training Stacked_LSTM...\n",
      "Epoch 1/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m82s\u001B[0m 86ms/step - loss: 258317504.0000 - val_loss: 235829472.0000\n",
      "Epoch 2/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 37ms/step - loss: 250696640.0000 - val_loss: 235686320.0000\n",
      "Epoch 3/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 49ms/step - loss: 252544992.0000 - val_loss: 235562832.0000\n",
      "Epoch 4/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 26ms/step - loss: 250869152.0000 - val_loss: 235445760.0000\n",
      "Epoch 5/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 44ms/step - loss: 253532128.0000 - val_loss: 235330848.0000\n",
      "Epoch 6/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 29ms/step - loss: 250490352.0000 - val_loss: 235217872.0000\n",
      "Epoch 7/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 31ms/step - loss: 260155824.0000 - val_loss: 235105552.0000\n",
      "Epoch 8/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 39ms/step - loss: 256090080.0000 - val_loss: 234994784.0000\n",
      "Epoch 9/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 25ms/step - loss: 260279648.0000 - val_loss: 234884112.0000\n",
      "Epoch 10/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 26ms/step - loss: 251643072.0000 - val_loss: 234774272.0000\n",
      "Epoch 11/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 32ms/step - loss: 257094832.0000 - val_loss: 234664336.0000\n",
      "Epoch 12/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 27ms/step - loss: 253290832.0000 - val_loss: 234555024.0000\n",
      "Epoch 13/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 24ms/step - loss: 252014192.0000 - val_loss: 234445696.0000\n",
      "Epoch 14/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 21ms/step - loss: 255649968.0000 - val_loss: 234336768.0000\n",
      "Epoch 15/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 30ms/step - loss: 255745152.0000 - val_loss: 234227920.0000\n",
      "Epoch 16/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 26ms/step - loss: 252196064.0000 - val_loss: 234118896.0000\n",
      "Epoch 17/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 28ms/step - loss: 252369504.0000 - val_loss: 234010320.0000\n",
      "Epoch 18/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 28ms/step - loss: 254564480.0000 - val_loss: 233901904.0000\n",
      "Epoch 19/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 27ms/step - loss: 252189088.0000 - val_loss: 233793648.0000\n",
      "Epoch 20/20\n",
      "\u001B[1m56/56\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 21ms/step - loss: 256840880.0000 - val_loss: 233685264.0000\n",
      "\u001B[1m18/18\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 226ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked_LSTM -> MAE: 16272.4161, RMSE: 17048.3503, R2: -10.2415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 2/25 [05:41<1:05:21, 170.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model for Baleares (daily): Stacked_LSTM\n",
      "{\n",
      "  \"MAE\": 16272.416133123454,\n",
      "  \"RMSE\": 17048.350313829047,\n",
      "  \"R2\": -10.241515105654507\n",
      "}\n",
      "\n",
      "Processing Baleares (hourly)\n",
      "Training LSTM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m45s\u001B[0m 32ms/step - loss: 402086.6875 - val_loss: 487929.0312\n",
      "Epoch 2/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m22s\u001B[0m 25ms/step - loss: 363691.5000 - val_loss: 444662.2188\n",
      "Epoch 3/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m45s\u001B[0m 29ms/step - loss: 328712.7188 - val_loss: 406182.4688\n",
      "Epoch 4/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m25s\u001B[0m 28ms/step - loss: 296241.2812 - val_loss: 370873.0938\n",
      "Epoch 5/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m26s\u001B[0m 29ms/step - loss: 263965.0938 - val_loss: 335447.7500\n",
      "Epoch 6/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m39s\u001B[0m 26ms/step - loss: 234888.5625 - val_loss: 303826.3438\n",
      "Epoch 7/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m44s\u001B[0m 28ms/step - loss: 209670.4844 - val_loss: 273070.1875\n",
      "Epoch 8/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 31ms/step - loss: 184100.6094 - val_loss: 245560.1875\n",
      "Epoch 9/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m39s\u001B[0m 45ms/step - loss: 162258.6562 - val_loss: 220193.2344\n",
      "Epoch 10/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 21ms/step - loss: 141303.0938 - val_loss: 196768.0156\n",
      "Epoch 11/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 22ms/step - loss: 122911.3047 - val_loss: 175281.2969\n",
      "Epoch 12/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 22ms/step - loss: 106246.5312 - val_loss: 155773.6875\n",
      "Epoch 13/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m24s\u001B[0m 28ms/step - loss: 93425.3516 - val_loss: 138174.3438\n",
      "Epoch 14/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m26s\u001B[0m 30ms/step - loss: 80396.7734 - val_loss: 122354.5391\n",
      "Epoch 15/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m47s\u001B[0m 35ms/step - loss: 69189.8438 - val_loss: 108350.2266\n",
      "Epoch 16/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 38ms/step - loss: 60810.3281 - val_loss: 96271.2422\n",
      "Epoch 17/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m33s\u001B[0m 38ms/step - loss: 52875.9805 - val_loss: 85919.1797\n",
      "Epoch 18/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m29s\u001B[0m 33ms/step - loss: 47472.7734 - val_loss: 77151.2734\n",
      "Epoch 19/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m24s\u001B[0m 27ms/step - loss: 42770.7539 - val_loss: 69781.3438\n",
      "Epoch 20/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m45s\u001B[0m 31ms/step - loss: 39625.2148 - val_loss: 63873.1953\n",
      "\u001B[1m275/275\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM -> MAE: 170.5137, RMSE: 229.6442, R2: 0.0384\n",
      "Training BiLSTM...\n",
      "Epoch 1/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m42s\u001B[0m 18ms/step - loss: 396956.2812 - val_loss: 459747.0938\n",
      "Epoch 2/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 17ms/step - loss: 334247.6562 - val_loss: 393178.9062\n",
      "Epoch 3/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 15ms/step - loss: 277983.7188 - val_loss: 335419.7188\n",
      "Epoch 4/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 16ms/step - loss: 230005.7656 - val_loss: 285717.5000\n",
      "Epoch 5/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 23ms/step - loss: 189435.8594 - val_loss: 238179.5469\n",
      "Epoch 6/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 19ms/step - loss: 153992.3750 - val_loss: 199520.6250\n",
      "Epoch 7/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 18ms/step - loss: 123510.7578 - val_loss: 166474.2656\n",
      "Epoch 8/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 19ms/step - loss: 98984.3828 - val_loss: 138539.5469\n",
      "Epoch 9/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 16ms/step - loss: 79453.7578 - val_loss: 114759.6406\n",
      "Epoch 10/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m22s\u001B[0m 18ms/step - loss: 63802.3320 - val_loss: 96277.1172\n",
      "Epoch 11/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 18ms/step - loss: 51700.0625 - val_loss: 82172.9141\n",
      "Epoch 12/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 15ms/step - loss: 45100.1367 - val_loss: 72135.4453\n",
      "Epoch 13/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 17ms/step - loss: 41262.4727 - val_loss: 65602.2656\n",
      "Epoch 14/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m22s\u001B[0m 18ms/step - loss: 38428.1250 - val_loss: 62594.3594\n",
      "Epoch 15/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 18ms/step - loss: 37937.7305 - val_loss: 60375.3750\n",
      "Epoch 16/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 18ms/step - loss: 37360.5430 - val_loss: 58999.8125\n",
      "Epoch 17/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 19ms/step - loss: 36964.1680 - val_loss: 56796.7852\n",
      "Epoch 18/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 20ms/step - loss: 35422.9414 - val_loss: 55818.3984\n",
      "Epoch 19/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m14s\u001B[0m 16ms/step - loss: 33913.3281 - val_loss: 51854.8594\n",
      "Epoch 20/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 13ms/step - loss: 32429.4609 - val_loss: 50336.6562\n",
      "\u001B[1m275/275\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 7ms/step\n",
      "BiLSTM -> MAE: 153.5009, RMSE: 205.9728, R2: 0.2265\n",
      "Training CNN_LSTM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 11ms/step - loss: 404140.8125 - val_loss: 488114.5938\n",
      "Epoch 2/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 12ms/step - loss: 366461.3750 - val_loss: 447930.3750\n",
      "Epoch 3/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 14ms/step - loss: 329706.0938 - val_loss: 410042.2500\n",
      "Epoch 4/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 11ms/step - loss: 298646.8438 - val_loss: 374852.1875\n",
      "Epoch 5/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 9ms/step - loss: 267808.7812 - val_loss: 341311.0938\n",
      "Epoch 6/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 11ms/step - loss: 239659.6562 - val_loss: 310348.2500\n",
      "Epoch 7/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 10ms/step - loss: 213448.7969 - val_loss: 281435.0312\n",
      "Epoch 8/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 12ms/step - loss: 192188.4531 - val_loss: 254161.9531\n",
      "Epoch 9/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 11ms/step - loss: 169539.3906 - val_loss: 229036.8750\n",
      "Epoch 10/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 11ms/step - loss: 150027.4688 - val_loss: 207114.4688\n",
      "Epoch 11/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 10ms/step - loss: 132471.0000 - val_loss: 185413.7812\n",
      "Epoch 12/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 10ms/step - loss: 114364.6875 - val_loss: 162478.7812\n",
      "Epoch 13/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 14ms/step - loss: 97780.0000 - val_loss: 144621.5156\n",
      "Epoch 14/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 12ms/step - loss: 85112.7422 - val_loss: 128443.6094\n",
      "Epoch 15/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 10ms/step - loss: 75102.4453 - val_loss: 114795.5234\n",
      "Epoch 16/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 10ms/step - loss: 64022.8359 - val_loss: 102755.8047\n",
      "Epoch 17/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 10ms/step - loss: 56323.3867 - val_loss: 91862.7109\n",
      "Epoch 18/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 9ms/step - loss: 51366.6211 - val_loss: 82356.3203\n",
      "Epoch 19/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 10ms/step - loss: 45395.7344 - val_loss: 72590.9766\n",
      "Epoch 20/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 10ms/step - loss: 39176.0234 - val_loss: 64225.2070\n",
      "\u001B[1m275/275\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 6ms/step\n",
      "CNN_LSTM -> MAE: 162.4657, RMSE: 229.7809, R2: 0.0373\n",
      "Training Stacked_LSTM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m25s\u001B[0m 21ms/step - loss: 388691.2812 - val_loss: 448146.1250\n",
      "Epoch 2/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 20ms/step - loss: 324472.5312 - val_loss: 383786.9688\n",
      "Epoch 3/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 21ms/step - loss: 270925.8438 - val_loss: 327022.4062\n",
      "Epoch 4/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 21ms/step - loss: 224159.0625 - val_loss: 276833.6562\n",
      "Epoch 5/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 20ms/step - loss: 184459.2500 - val_loss: 232588.6719\n",
      "Epoch 6/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 21ms/step - loss: 148431.3281 - val_loss: 193975.0469\n",
      "Epoch 7/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 23ms/step - loss: 118820.4141 - val_loss: 160817.7188\n",
      "Epoch 8/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 27ms/step - loss: 95205.1094 - val_loss: 132728.7188\n",
      "Epoch 9/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m26s\u001B[0m 29ms/step - loss: 75745.0625 - val_loss: 109635.7344\n",
      "Epoch 10/20\n",
      "\u001B[1m877/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 30ms/step - loss: 59160.5469 - val_loss: 91217.7812\n",
      "Epoch 11/20\n",
      "\u001B[1m876/877\u001B[0m \u001B[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m\u001B[37mâ”\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 48507.0078"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a49b8fa0e386a39"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
